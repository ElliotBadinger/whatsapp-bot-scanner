services:
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: ["redis-server", "--save", "60", "1", "--appendonly", "yes", "--maxmemory", "256mb", "--maxmemory-policy", "noeviction"]
    mem_limit: 512m
    cpus: '0.5'
    pids_limit: 100
    ulimits:
      nofile:
        soft: 1024
        hard: 2048
    ports:
      - "6379:6379"
    volumes:
      - redisdata:/data
    networks: [internal]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    read_only: true
    tmpfs:
      - /tmp
    security_opt:
      - no-new-privileges:true
    user: "999:999"
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID

  migrate:
    build:
      context: .
      dockerfile: docker/Dockerfile
      target: migrate
      network: host
    working_dir: /app
    env_file: [.env]
    mem_limit: 512m
    cpus: '0.5'
    pids_limit: 50
    ulimits:
      nofile:
        soft: 1024
        hard: 2048
    volumes:
      - ./storage:/app/storage:rw
    depends_on:
      redis:
        condition: service_healthy
    networks: [internal]
    restart: "no"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    read_only: true
    tmpfs:
      - /tmp

  wa-client:
    build:
      context: .
      dockerfile: docker/Dockerfile
      # Use wa-client-baileys for Baileys (lightweight), wa-client for wwebjs (Puppeteer)
      target: ${WA_BUILD_TARGET:-wa-client-baileys}
      network: host
    env_file: [.env]
    depends_on:
      redis:
        condition: service_healthy
    mem_limit: 1g
    cpus: '1.0'
    pids_limit: 200
    ulimits:
      nofile:
        soft: 4096
        hard: 8192
    networks: [internal, public]
    ports:
      - "${WA_CLIENT_PORT:-3005}:3001"
    environment:
      - WA_HTTP_PORT=3001
      - NODE_OPTIONS=--max-old-space-size=768
      - REDIS_URL=redis://redis:6379/0
      - WA_LIBRARY=${WA_LIBRARY:-baileys}
    volumes:
      - wa_session:/app/services/wa-client/data:rw
      - ./storage:/app/storage:rw
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL","wget -qO- http://localhost:3001/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    read_only: true
    tmpfs:
      - /tmp

  scan-orchestrator:
    build:
      context: .
      dockerfile: docker/Dockerfile
      target: scan-orchestrator
      network: host
    env_file: [.env]
    depends_on:
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    networks: [internal]
    mem_limit: 1g
    cpus: '1.0'
    pids_limit: 150
    ulimits:
      nofile:
        soft: 2048
        hard: 4096
    ports:
      # Scan Orchestrator API (exposed for health checks and debugging)
      - "${SCAN_ORCHESTRATOR_PORT:-3003}:3001"
    environment:
      - NODE_OPTIONS=--max-old-space-size=768
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./storage:/app/storage:rw
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL","wget -qO- http://localhost:3001/healthz || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    read_only: true
    tmpfs:
      - /tmp

  control-plane:
    build:
      context: .
      dockerfile: docker/Dockerfile
      target: control-plane
      network: host
    env_file: [.env]
    depends_on:
      migrate:
        condition: service_completed_successfully
    networks: [internal]
    mem_limit: 512m
    cpus: '0.5'
    pids_limit: 100
    ulimits:
      nofile:
        soft: 1024
        hard: 2048
    environment:
      - NODE_OPTIONS=--max-old-space-size=384
    volumes:
      - ./storage:/app/storage:rw
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL","wget --header=\"Authorization: Bearer ${CONTROL_PLANE_API_TOKEN}\" -qO- http://127.0.0.1:8080/healthz || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 10
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    read_only: true
    tmpfs:
      - /tmp

  reverse-proxy:
    image: nginx:alpine
    depends_on:
      - control-plane
    mem_limit: 256m
    cpus: '0.25'
    pids_limit: 50
    ulimits:
      nofile:
        soft: 512
        hard: 1024
    volumes:
      - ./reverse-proxy/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./services/landing-page:/usr/share/nginx/html:ro
    ports:
      - "${REVERSE_PROXY_PORT:-8088}:8088"
    networks: [internal, public]
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - NET_BIND_SERVICE
    read_only: true
    tmpfs:
      - /var/cache/nginx
      - /var/run
      - /tmp

  grafana:
    image: grafana/grafana:latest
    depends_on:
      - prometheus
    ports:
      - "${GRAFANA_PORT:-3002}:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/etc/grafana/dashboards:ro
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    networks: [internal]
    restart: unless-stopped
    mem_limit: 512m
    cpus: '0.5'
    pids_limit: 100
    ulimits:
      nofile:
        soft: 1024
        hard: 2048
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    tmpfs:
      - /tmp
      - /var/lib/grafana/tmp

  prometheus:
    image: prom/prometheus:latest
    command: ["--config.file=/etc/prometheus/prometheus.yml"]
    mem_limit: 1g
    cpus: '0.5'
    pids_limit: 100
    ulimits:
      nofile:
        soft: 1024
        hard: 2048
    ports:
      - "9091:9090"
    volumes:
      - ./observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks: [internal]
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    tmpfs:
      - /tmp
      - /prometheus/tmp

  uptime-kuma:
    image: louislam/uptime-kuma:1
    restart: unless-stopped
    volumes:
      - uptime_kuma_data:/app/data
    ports:
      - "${UPTIME_KUMA_PORT:-3001}:3001"
    networks: [internal]
    mem_limit: 256m
    cpus: '0.25'
    pids_limit: 50
    ulimits:
      nofile:
        soft: 512
        hard: 1024
    environment:
      - UPTIME_KUMA_PORT=3001
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:3001 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    read_only: true
    tmpfs:
      - /tmp
      - /app/data/tmp

networks:
  internal:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16
          ip_range: 172.30.1.0/24
          gateway: 172.30.1.1
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
  public:
    driver: bridge
    ipam:
      config:
        - subnet: 172.31.0.0/16
          ip_range: 172.31.1.0/24
          gateway: 172.31.1.1
    driver_opts:
      com.docker.network.bridge.enable_icc: "false"
      com.docker.network.bridge.enable_ip_masquerade: "true"

volumes:
  wa_session:
  redisdata:
  uptime_kuma_data:
  grafana_data:
  prometheus_data:
